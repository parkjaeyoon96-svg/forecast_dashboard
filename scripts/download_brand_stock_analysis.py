"""
ë¸Œëœë“œë³„ í˜„í™© - ë‹¹ì‹œì¦Œì˜ë¥˜/ACC ì¬ê³ ì£¼ìˆ˜ ë¶„ì„ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/download_brand_stock_analysis.py --update-date 2025-11-24
    python scripts/download_brand_stock_analysis.py  # ê¸°ë³¸ê°’: ì˜¤ëŠ˜ ë‚ ì§œ
    python scripts/download_brand_stock_analysis.py --no-js  # JS íŒŒì¼ ìƒì„± ì•ˆ í•¨
    
ì¶œë ¥:
    - raw/202511/ETC/ë‹¹ì‹œì¦Œì˜ë¥˜_ë¸Œëœë“œë³„í˜„í™©_YYYYMMDD.csv
    - raw/202511/ETC/ACC_ì¬ê³ ì£¼ìˆ˜ë¶„ì„_YYYYMMDD.csv
    - public/brand_stock_analysis_YYYYMMDD.js (ëŒ€ì‹œë³´ë“œìš©)
"""

import os
import sys
import argparse
import json
from pathlib import Path
from datetime import datetime, timedelta
from decimal import Decimal
from dotenv import load_dotenv
import snowflake.connector
import pandas as pd

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# .env íŒŒì¼ ë¡œë“œ
env_path = project_root / '.env'
if env_path.exists():
    load_dotenv(env_path)
else:
    print("âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì½ìŠµë‹ˆë‹¤.")


def get_snowflake_connection():
    """Snowflake ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒì„±"""
    try:
        conn = snowflake.connector.connect(
            account=os.getenv('SNOWFLAKE_ACCOUNT'),
            user=os.getenv('SNOWFLAKE_USERNAME'),
            password=os.getenv('SNOWFLAKE_PASSWORD'),
            warehouse=os.getenv('SNOWFLAKE_WAREHOUSE'),
            database=os.getenv('SNOWFLAKE_DATABASE')
        )
        print("[ì„±ê³µ] Snowflake ì—°ê²° ì„±ê³µ!")
        return conn
    except Exception as e:
        print(f"[ì˜¤ë¥˜] Snowflake ì—°ê²° ì‹¤íŒ¨: {e}")
        raise


def execute_query(conn, query: str) -> pd.DataFrame:
    """ì¿¼ë¦¬ ì‹¤í–‰ ë° DataFrame ë°˜í™˜"""
    try:
        cursor = conn.cursor()
        cursor.execute(query)
        columns = [desc[0] for desc in cursor.description]
        data = cursor.fetchall()
        df = pd.DataFrame(data, columns=columns)
        cursor.close()
        return df
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise


def calculate_dates(update_date: datetime) -> dict:
    """
    ì—…ë°ì´íŠ¸ ì¼ì ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¶œ ì¡°íšŒ ë‚ ì§œ ê³„ì‚°
    
    Args:
        update_date: ì—…ë°ì´íŠ¸ ì¼ì (ì˜ˆ: 2025-11-24)
        
    Returns:
        dict: ê³„ì‚°ëœ ë‚ ì§œ ì •ë³´
            - cy_week_end: ë‹¹ë…„ ì£¼ê°„ ì¢…ë£Œì¼ (ì—…ë°ì´íŠ¸ ì „ë‚ )
            - cy_week_start: ë‹¹ë…„ ì£¼ê°„ ì‹œì‘ì¼ (ì¢…ë£Œì¼ - 6ì¼)
            - py_week_end: ì „ë…„ ë™ì£¼ì°¨ ì¢…ë£Œì¼ (364ì¼ ì „)
            - py_week_start: ì „ë…„ ë™ì£¼ì°¨ ì‹œì‘ì¼
            - cy_season: ë‹¹ë…„ ì‹œì¦Œ ì½”ë“œ
            - py_season: ì „ë…„ ì‹œì¦Œ ì½”ë“œ
            - py_season_end: ì „ë…„ ì‹œì¦Œ ë§ˆê°ì¼
    """
    # ë‹¹ë…„ ì£¼ê°„: ì—…ë°ì´íŠ¸ì¼ ì „ ì£¼ (ì›”~ì¼)
    cy_week_end = update_date - timedelta(days=1)  # ì—…ë°ì´íŠ¸ ì „ë‚  (ì¼ìš”ì¼)
    cy_week_start = cy_week_end - timedelta(days=6)  # ì›”ìš”ì¼
    
    # ì „ë…„ ë™ì£¼ì°¨: 364ì¼ ì „ (52ì£¼ = 364ì¼, ê°™ì€ ìš”ì¼)
    py_week_end = cy_week_end - timedelta(days=364)
    py_week_start = cy_week_start - timedelta(days=364)
    
    # ì‹œì¦Œ ì½”ë“œ ê²°ì • (F: ê°€ì„/ê²¨ìš¸, S: ë´„/ì—¬ë¦„)
    # 8ì›”~2ì›”: Fì‹œì¦Œ, 3ì›”~7ì›”: Sì‹œì¦Œ
    cy_year = update_date.year
    cy_month = update_date.month
    
    if cy_month >= 8 or cy_month <= 2:
        # Fì‹œì¦Œ (ê°€ì„/ê²¨ìš¸)
        if cy_month <= 2:
            cy_season = f"{(cy_year - 1) % 100:02d}F"  # 1,2ì›”ì€ ì „ë…„ë„ Fì‹œì¦Œ
            py_season = f"{(cy_year - 2) % 100:02d}F"
        else:
            cy_season = f"{cy_year % 100:02d}F"
            py_season = f"{(cy_year - 1) % 100:02d}F"
    else:
        # Sì‹œì¦Œ (ë´„/ì—¬ë¦„)
        cy_season = f"{cy_year % 100:02d}S"
        py_season = f"{(cy_year - 1) % 100:02d}S"
    
    # ì „ë…„ ì‹œì¦Œ ë§ˆê°ì¼ (Fì‹œì¦Œ: 2ì›”ë§, Sì‹œì¦Œ: 7ì›”ë§)
    if 'F' in cy_season:
        py_season_end_year = int('20' + py_season[:2]) + 1
        py_season_end = datetime(py_season_end_year, 2, 28)
    else:
        py_season_end_year = int('20' + py_season[:2])
        py_season_end = datetime(py_season_end_year, 7, 31)
    
    # 4ì£¼ í‰ê·  ê³„ì‚°ì„ ìœ„í•œ ë‚ ì§œ
    cy_4w_start = cy_week_end - timedelta(days=21)  # 4ì£¼ ì‹œì‘
    py_4w_start = py_week_end - timedelta(days=21)
    
    return {
        'update_date': update_date,
        'cy_week_start': cy_week_start,
        'cy_week_end': cy_week_end,
        'py_week_start': py_week_start,
        'py_week_end': py_week_end,
        'cy_season': cy_season,
        'py_season': py_season,
        'py_season_end': py_season_end,
        'cy_4w_start': cy_4w_start,
        'py_4w_start': py_4w_start
    }


def build_clothing_query(dates: dict) -> str:
    """
    ë‹¹ì‹œì¦Œì˜ë¥˜ ë¶„ì„ ì¿¼ë¦¬ ìƒì„± (ACC ì œì™¸)
    """
    cy_week_end = dates['cy_week_end'].strftime('%Y-%m-%d')
    py_week_end = dates['py_week_end'].strftime('%Y-%m-%d')
    py_season_end = dates['py_season_end'].strftime('%Y-%m-%d')
    cy_season = dates['cy_season']
    py_season = dates['py_season']
    
    query = f"""
WITH RDS AS (
  SELECT
      U.BRD_CD,
      B.ITEM AS MASTER,
      B.PARENT_PRDT_KIND_NM,
      B.PRDT_KIND_NM,
      B.ITEM,
      MAX(B.ITEM_NM) AS ITEM_NM,
      SUM(W_QTY_PY)                   AS W_QTY_PY,
      SUM(W_TAG_AMG_PY)               AS W_TAG_AMG_PY,
      SUM(W_SALE_AMT_PY)              AS W_SALE_AMT_PY,
      SUM(AC_ORD_QTY_PY)              AS AC_ORD_QTY_PY,
      SUM(AC_ORD_TAG_AMT_PY)          AS AC_ORD_TAG_AMT_PY,
      SUM(AC_STOR_QTY_KOR_PY)         AS AC_STOR_QTY_KOR_PY,
      SUM(AC_STOR_TAG_AMT_KOR_PY)     AS AC_STOR_TAG_AMT_KOR_PY,
      SUM(AC_QTY_PY)                  AS AC_QTY_PY,
      SUM(AC_TAG_AMG_PY)              AS AC_TAG_AMG_PY,
      SUM(AC_SALE_AMT_PY)             AS AC_SALE_AMT_PY,
      SUM(STOCK_QTY_PY)               AS STOCK_QTY_PY,
      SUM(STOCK_TAG_AMT_PY)           AS STOCK_TAG_AMT_PY,
      SUM(AC_ORD_QTY_PY_END)          AS AC_ORD_QTY_PY_END,
      SUM(AC_ORD_TAG_AMT_PY_END)      AS AC_ORD_TAG_AMT_PY_END,
      SUM(AC_STOR_QTY_KOR_PY_END)     AS AC_STOR_QTY_KOR_PY_END,
      SUM(AC_STOR_TAG_AMT_KOR_PY_END) AS AC_STOR_TAG_AMT_KOR_PY_END,
      SUM(QTY_PY_END)                 AS QTY_PY_END,
      SUM(TAG_AMT_PY_END)             AS TAG_AMT_PY_END,
      SUM(SALE_AMT_PY_END)            AS SALE_AMT_PY_END,
      SUM(W_QTY)                      AS W_QTY,
      SUM(W_TAG_AMG)                  AS W_TAG_AMG,
      SUM(W_SALE_AMT)                 AS W_SALE_AMT,
      SUM(AC_ORD_QTY)                 AS AC_ORD_QTY,
      SUM(AC_ORD_TAG_AMT)             AS AC_ORD_TAG_AMT,
      SUM(AC_STOR_QTY_KOR)            AS AC_STOR_QTY_KOR,
      SUM(AC_STOR_TAG_AMT_KOR)        AS AC_STOR_TAG_AMT_KOR,
      SUM(AC_QTY)                     AS AC_QTY,
      SUM(AC_TAG_AMG)                 AS AC_TAG_AMG,
      SUM(AC_SALE_AMT)                AS AC_SALE_AMT,
      SUM(STOCK_QTY)                  AS STOCK_QTY,
      SUM(STOCK_TAG_AMT)              AS STOCK_TAG_AMT
  FROM (
      /* 1) ì „ë…„ ì£¼ê°„ */
      SELECT
          D.PRDT_CD, D.BRD_CD,
          (D.SALE_NML_TAG_AMT_CNS + D.SALE_RET_TAG_AMT_CNS) AS W_TAG_AMG_PY,
          (D.SALE_NML_QTY_CNS      + D.SALE_RET_QTY_CNS)    AS W_QTY_PY,
          (D.SALE_NML_SALE_AMT_CNS + D.SALE_RET_SALE_AMT_CNS) AS W_SALE_AMT_PY,
          0::NUMBER AS AC_ORD_QTY_PY, 0::NUMBER AS AC_ORD_TAG_AMT_PY,
          0::NUMBER AS AC_STOR_QTY_KOR_PY, 0::NUMBER AS AC_STOR_TAG_AMT_KOR_PY,
          0::NUMBER AS AC_TAG_AMG_PY,  0::NUMBER AS AC_QTY_PY, 0::NUMBER AS AC_SALE_AMT_PY,
          0::NUMBER AS STOCK_QTY_PY,   0::NUMBER AS STOCK_TAG_AMT_PY,
          0::NUMBER AS AC_ORD_QTY_PY_END, 0::NUMBER AS AC_ORD_TAG_AMT_PY_END,
          0::NUMBER AS AC_STOR_QTY_KOR_PY_END, 0::NUMBER AS AC_STOR_TAG_AMT_KOR_PY_END,
          0::NUMBER AS QTY_PY_END, 0::NUMBER AS TAG_AMT_PY_END, 0::NUMBER AS SALE_AMT_PY_END,
          0::NUMBER AS W_TAG_AMG, 0::NUMBER AS W_QTY, 0::NUMBER AS W_SALE_AMT,
          0::NUMBER AS AC_ORD_QTY, 0::NUMBER AS AC_ORD_TAG_AMT,
          0::NUMBER AS AC_STOR_QTY_KOR, 0::NUMBER AS AC_STOR_TAG_AMT_KOR,
          0::NUMBER AS AC_TAG_AMG,  0::NUMBER AS AC_QTY, 0::NUMBER AS AC_SALE_AMT,
          0::NUMBER AS STOCK_QTY,   0::NUMBER AS STOCK_TAG_AMT
      FROM PRCS.DW_SCS_D D
      WHERE D.SESN IN ('{py_season}')
        AND D.DT BETWEEN DATE '{py_week_end}' - 6 AND DATE '{py_week_end}'
      UNION ALL
      /* 2) ì „ë…„ ëˆ„ì  ìŠ¤ëƒ…ìƒ· */
      SELECT
          A.PRDT_CD, A.BRD_CD,
          0,0,0,
          A.AC_ORD_QTY, A.AC_ORD_TAG_AMT, A.AC_STOR_QTY_KOR, A.AC_STOR_TAG_AMT_KOR,
          (A.AC_SALE_NML_TAG_AMT_CNS + A.AC_SALE_RET_TAG_AMT_CNS),
          (A.AC_SALE_NML_QTY_CNS     + A.AC_SALE_RET_QTY_CNS),
          (A.AC_SALE_NML_SALE_AMT_CNS+ A.AC_SALE_RET_SALE_AMT_CNS),
          A.STOCK_QTY, A.STOCK_TAG_AMT,
          0,0,0,0, 0,0,0,
          0,0,0,
          0,0,0,0, 0,0,0, 0,0
      FROM PRCS.DW_SCS_DACUM A
      WHERE A.SESN IN ('{py_season}')
        AND DATE '{py_week_end}' BETWEEN A.START_DT AND A.END_DT
      UNION ALL
      /* 3) ì „ë…„ ì‹œì¦Œ ë§ˆê° ìŠ¤ëƒ…ìƒ· */
      SELECT
          A.PRDT_CD, A.BRD_CD,
          0,0,0,
          0,0,0,0, 0,0,0, 0,0,
          A.AC_ORD_QTY, A.AC_ORD_TAG_AMT, A.AC_STOR_QTY_KOR, A.AC_STOR_TAG_AMT_KOR,
          (A.AC_SALE_NML_QTY_CNS     + A.AC_SALE_RET_QTY_CNS)      AS QTY_PY_END,
          (A.AC_SALE_NML_TAG_AMT_CNS + A.AC_SALE_RET_TAG_AMT_CNS)  AS TAG_AMT_PY_END,
          (A.AC_SALE_NML_SALE_AMT_CNS+ A.AC_SALE_RET_SALE_AMT_CNS) AS SALE_AMT_PY_END,
          0,0,0,
          0,0,0,0, 0,0,0, 0,0
      FROM PRCS.DW_SCS_DACUM A
      WHERE A.SESN IN ('{py_season}')
        AND DATE '{py_season_end}' BETWEEN A.START_DT AND A.END_DT
      UNION ALL
      /* 4) ë‹¹í•´ ì£¼ê°„ */
      SELECT
          D.PRDT_CD, D.BRD_CD,
          0,0,0,
          0,0,0,0, 0,0,0, 0,0,
          0,0,0,0, 0,0,0,
          (D.SALE_NML_TAG_AMT_CNS + D.SALE_RET_TAG_AMT_CNS),
          (D.SALE_NML_QTY_CNS     + D.SALE_RET_QTY_CNS),
          (D.SALE_NML_SALE_AMT_CNS+ D.SALE_RET_SALE_AMT_CNS),
          0,0,0,0, 0,0,0, 0,0
      FROM PRCS.DW_SCS_D D
      WHERE D.SESN IN ('{cy_season}')
        AND D.DT BETWEEN DATE '{cy_week_end}' - 6 AND DATE '{cy_week_end}'
      UNION ALL
      /* 5) ë‹¹í•´ ëˆ„ì  ìŠ¤ëƒ…ìƒ· */
      SELECT
          A.PRDT_CD, A.BRD_CD,
          0,0,0,
          0,0,0,0, 0,0,0, 0,0,
          0,0,0,0, 0,0,0,
          0,0,0,
          A.AC_ORD_QTY, A.AC_ORD_TAG_AMT, A.AC_STOR_QTY_KOR, A.AC_STOR_TAG_AMT_KOR,
          (A.AC_SALE_NML_TAG_AMT_CNS + A.AC_SALE_RET_TAG_AMT_CNS),
          (A.AC_SALE_NML_QTY_CNS     + A.AC_SALE_RET_QTY_CNS),
          (A.AC_SALE_NML_SALE_AMT_CNS+ A.AC_SALE_RET_SALE_AMT_CNS),
          A.STOCK_QTY, A.STOCK_TAG_AMT
      FROM PRCS.DW_SCS_DACUM A
      WHERE A.SESN IN ('{cy_season}')
        AND DATE '{cy_week_end}' BETWEEN A.START_DT AND A.END_DT
  ) U
  JOIN PRCS.DB_PRDT B ON U.PRDT_CD = B.PRDT_CD
  GROUP BY
      U.BRD_CD, B.PARENT_PRDT_KIND_NM, B.PRDT_KIND_NM, B.ITEM
)
SELECT
    BRD_CD                                         AS "ë¸Œëœë“œ",
    PARENT_PRDT_KIND_NM                            AS "ëŒ€ë¶„ë¥˜",
    PRDT_KIND_NM                                   AS "ì¤‘ë¶„ë¥˜",
    ITEM                                           AS "ì•„ì´í…œì½”ë“œ",
    ITEM_NM                                        AS "ì•„ì´í…œëª…(í•œê¸€)",
    AC_ORD_TAG_AMT                                 AS "ë°œì£¼(TAG)",
    ROUND( AC_ORD_TAG_AMT / NULLIF(AC_ORD_TAG_AMT_PY, 0), 4 ) AS "ì „ë…„ë¹„(ë°œì£¼)",
    W_TAG_AMG                                      AS "ì£¼ê°„íŒë§¤ë§¤ì¶œ(TAG)",
    ROUND( W_TAG_AMG / NULLIF(W_TAG_AMG_PY, 0), 4 )           AS "ì „ë…„ë¹„(ì£¼ê°„)",
    AC_TAG_AMG                                     AS "ëˆ„ì íŒë§¤ë§¤ì¶œ(TAG)",
    ROUND( AC_TAG_AMG / NULLIF(AC_TAG_AMG_PY, 0), 4 )         AS "ì „ë…„ë¹„(ëˆ„ì )",
    ROUND( AC_TAG_AMG / NULLIF(AC_STOR_TAG_AMT_KOR, 0), 4 )   AS "ëˆ„ì íŒë§¤ìœ¨ë‹¹ë…„",
    ROUND(
      (AC_TAG_AMG   / NULLIF(AC_STOR_TAG_AMT_KOR,    0))
      - (AC_TAG_AMG_PY / NULLIF(AC_STOR_TAG_AMT_KOR_PY, 0)),
      4
    )                                               AS "ëˆ„ì íŒë§¤ìœ¨ì°¨ì´",
    ROUND( TAG_AMT_PY_END / NULLIF(AC_STOR_TAG_AMT_KOR_PY_END, 0), 4 ) AS "ì „ë…„ë§ˆê°íŒë§¤ìœ¨",
    -- íŒë§¤ìœ¨ ì¬ê³„ì‚°ì„ ìœ„í•œ ì›ë³¸ ë°ì´í„°
    AC_TAG_AMG                                     AS "ëˆ„ì íŒë§¤TAGê°€",
    AC_STOR_TAG_AMT_KOR                            AS "ëˆ„ì ì…ê³ TAGê°€",
    AC_TAG_AMG_PY                                  AS "ì „ë…„ëˆ„ì íŒë§¤TAGê°€",
    AC_STOR_TAG_AMT_KOR_PY                         AS "ì „ë…„ëˆ„ì ì…ê³ TAGê°€",
    TAG_AMT_PY_END                                 AS "ì „ë…„ë§ˆê°ëˆ„ì íŒë§¤TAGê°€",
    AC_STOR_TAG_AMT_KOR_PY_END                     AS "ì „ë…„ë§ˆê°ëˆ„ì ì…ê³ TAGê°€"
FROM RDS
WHERE PARENT_PRDT_KIND_NM <> 'ACC'
ORDER BY BRD_CD, PARENT_PRDT_KIND_NM, PRDT_KIND_NM, ITEM
"""
    return query


def build_acc_stock_query(dates: dict) -> str:
    """
    ACC ì¬ê³ ì£¼ìˆ˜ ë¶„ì„ ì¿¼ë¦¬ ìƒì„±
    """
    cy_week_end = dates['cy_week_end'].strftime('%Y-%m-%d')
    cy_week_start = dates['cy_week_start'].strftime('%Y-%m-%d')
    py_week_end = dates['py_week_end'].strftime('%Y-%m-%d')
    py_week_start = dates['py_week_start'].strftime('%Y-%m-%d')
    cy_4w_start = dates['cy_4w_start'].strftime('%Y-%m-%d')
    py_4w_start = dates['py_4w_start'].strftime('%Y-%m-%d')
    
    query = f"""
WITH
base AS (
  SELECT 
    a.end_dt,
    a.brd_cd,
    b.item,
    b.item_nm,
    b.prdt_kind_nm,
    b.parent_prdt_kind_nm,
    (a.sale_nml_sale_amt_cns + a.sale_ret_sale_amt_cns) AS sale_amt,
    (a.sale_nml_qty_cns  + a.sale_ret_qty_cns)          AS sale_qty,
    a.stock_qty,
    a.stock_tag_amt AS stock_tag_amt
  FROM prcs.db_scs_w a
  JOIN prcs.db_prdt  b
    ON a.prdt_cd = b.prdt_cd
   AND a.brd_cd  = b.brd_cd
  WHERE b.parent_prdt_kind_nm = 'ACC'
),

-- CY: ë‹¹ë…„ ì£¼ê°„
cy AS (
  SELECT 
    brd_cd, item,
    MAX(item_nm)       AS item_nm,
    MAX(prdt_kind_nm)  AS prdt_kind_nm,
    SUM(sale_amt)      AS sale_amt_cy,
    SUM(sale_qty)      AS sale_qty_cy
  FROM base
  WHERE end_dt BETWEEN '{cy_week_start}' AND '{cy_week_end}'
  GROUP BY brd_cd, item
),

-- PY: ì „ë…„ ë™ì£¼ì°¨ (364ì¼ ì „)
py AS (
  SELECT 
    brd_cd, item,
    SUM(sale_amt) AS sale_amt_py,
    SUM(sale_qty) AS sale_qty_py
  FROM base
  WHERE end_dt BETWEEN '{py_week_start}' AND '{py_week_end}'
  GROUP BY brd_cd, item
),

-- CY 4ì£¼ í‰ê· 
avg4w AS (
  SELECT 
    brd_cd, item,
    SUM(sale_qty)::numeric / 4.0 AS sale_qty_4w_avg
  FROM base
  WHERE end_dt BETWEEN '{cy_4w_start}' AND '{cy_week_end}'
  GROUP BY brd_cd, item
),

-- PY 4ì£¼ í‰ê·  (364ì¼ ì „)
avg4w_py AS (
  SELECT 
    brd_cd, item,
    SUM(sale_qty)::numeric / 4.0 AS sale_qty_4w_avg_py
  FROM base
  WHERE end_dt BETWEEN '{py_4w_start}' AND '{py_week_end}'
  GROUP BY brd_cd, item
),

-- CY ì¬ê³ 
stk AS (
  SELECT 
    brd_cd, item,
    SUM(stock_qty) AS stock_qty_asof,
    SUM(stock_tag_amt) AS stock_tag_amt_asof
  FROM base
  WHERE end_dt = '{cy_week_end}'
  GROUP BY brd_cd, item
),

-- PY ì¬ê³  (364ì¼ ì „)
stk_py AS (
  SELECT 
    brd_cd, item,
    SUM(stock_qty) AS stock_qty_asof_py,
    SUM(stock_tag_amt) AS stock_tag_amt_asof_py
  FROM base
  WHERE end_dt = '{py_week_end}'
  GROUP BY brd_cd, item
),

merge AS (
  SELECT
    COALESCE(c.brd_cd, p.brd_cd, a.brd_cd, ap.brd_cd, s.brd_cd, sp.brd_cd) AS brd_cd,
    COALESCE(c.item,   p.item,   a.item,   ap.item,   s.item,   sp.item)   AS item,
    COALESCE(c.item_nm, c2.item_nm)             AS item_nm,
    COALESCE(c.prdt_kind_nm, c2.prdt_kind_nm)  AS prdt_kind_nm,
    COALESCE(c.sale_amt_cy, 0)                  AS sale_amt_cy,
    COALESCE(p.sale_amt_py, 0)                  AS sale_amt_py,
    COALESCE(c.sale_qty_cy, 0)                  AS sale_qty_cy,
    COALESCE(a.sale_qty_4w_avg, 0)::numeric     AS sale_qty_4w_avg,
    COALESCE(ap.sale_qty_4w_avg_py, 0)::numeric AS sale_qty_4w_avg_py,
    COALESCE(s.stock_qty_asof, 0)               AS stock_qty_asof,
    COALESCE(sp.stock_qty_asof_py, 0)           AS stock_qty_asof_py,
    COALESCE(s.stock_tag_amt_asof, 0)           AS stock_tag_amt_asof,
    COALESCE(sp.stock_tag_amt_asof_py, 0)      AS stock_tag_amt_asof_py
  FROM cy c
  LEFT JOIN (
    SELECT brd_cd, item, MAX(item_nm) AS item_nm, MAX(prdt_kind_nm) AS prdt_kind_nm
    FROM base GROUP BY brd_cd, item
  ) c2 ON c2.brd_cd = c.brd_cd AND c2.item = c.item

  FULL OUTER JOIN py       p  ON c.brd_cd = p.brd_cd  AND c.item = p.item
  FULL OUTER JOIN avg4w    a  ON COALESCE(c.brd_cd,p.brd_cd) = a.brd_cd
                              AND COALESCE(c.item,  p.item)  = a.item
  FULL OUTER JOIN avg4w_py ap ON COALESCE(c.brd_cd,p.brd_cd,a.brd_cd) = ap.brd_cd
                              AND COALESCE(c.item,  p.item,  a.item)  = ap.item
  FULL OUTER JOIN stk      s  ON COALESCE(c.brd_cd,p.brd_cd,a.brd_cd,ap.brd_cd) = s.brd_cd
                              AND COALESCE(c.item,  p.item,  a.item,  ap.item)  = s.item
  FULL OUTER JOIN stk_py   sp ON COALESCE(c.brd_cd,p.brd_cd,a.brd_cd,ap.brd_cd,s.brd_cd) = sp.brd_cd
                              AND COALESCE(c.item,  p.item,  a.item,  ap.item,  s.item)  = sp.item
),

tot AS (
  SELECT brd_cd, SUM(sale_amt_cy) AS total_sale_amt_cy
  FROM merge
  GROUP BY brd_cd
)

SELECT
  m.brd_cd                               AS "ë¸Œëœë“œì½”ë“œ",
  m.prdt_kind_nm                         AS "ì¹´í…Œê³ ë¦¬",
  m.item                                 AS "ì•„ì´í…œ",
  m.item_nm                              AS "ì•„ì´í…œëª…",
  m.sale_qty_cy::bigint                  AS "íŒë§¤ìˆ˜ëŸ‰",
  m.sale_amt_cy::bigint                  AS "íŒë§¤ë§¤ì¶œ",

  CASE 
    WHEN m.sale_amt_py = 0 THEN NULL
    ELSE ROUND((m.sale_amt_cy::numeric / NULLIF(m.sale_amt_py,0)) * 100)::int || '%'
  END                                    AS "ì „ë…„ë¹„",

  CASE 
    WHEN t.total_sale_amt_cy = 0 THEN '0%'
    ELSE ROUND((m.sale_amt_cy::numeric / t.total_sale_amt_cy) * 100)::int || '%'
  END                                    AS "ë¹„ì¤‘",

  ROUND(m.sale_qty_4w_avg, 2)            AS "4ì£¼í‰ê· íŒë§¤ëŸ‰",
  m.stock_qty_asof::bigint               AS "ì¬ê³ ",
  m.stock_tag_amt_asof::bigint          AS "ì¬ê³ ê¸ˆì•¡",

  ROUND(
    CASE WHEN m.sale_qty_4w_avg > 0 
         THEN m.stock_qty_asof::numeric / m.sale_qty_4w_avg
         ELSE NULL END
  , 1)                                   AS "ì¬ê³ ì£¼ìˆ˜",

  ROUND(
    CASE WHEN m.sale_qty_4w_avg_py > 0 
         THEN m.stock_qty_asof_py::numeric / m.sale_qty_4w_avg_py
         ELSE NULL END
  , 1)                                   AS "ì „ë…„ì¬ê³ ì£¼ìˆ˜",

  ROUND(
    (
      CASE WHEN m.sale_qty_4w_avg > 0 
           THEN m.stock_qty_asof::numeric / m.sale_qty_4w_avg
           ELSE NULL END
      -
      CASE WHEN m.sale_qty_4w_avg_py > 0 
           THEN m.stock_qty_asof_py::numeric / m.sale_qty_4w_avg_py
           ELSE NULL END
    )
  , 1)                                   AS "ì¬ê³ ì£¼ìˆ˜ì°¨ì´(ë‹¹ë…„-ì „ë…„)"

FROM merge m
JOIN tot  t ON m.brd_cd = t.brd_cd
WHERE m.sale_amt_cy    <> 0
   OR m.sale_qty_cy    <> 0
   OR m.stock_qty_asof <> 0
   OR m.stock_tag_amt_asof <> 0
ORDER BY m.brd_cd, m.sale_amt_cy DESC
"""
    return query


def save_to_js(clothing_df: pd.DataFrame, acc_df: pd.DataFrame, 
               dates: dict, output_path: Path) -> None:
    """
    ë°ì´í„°ë¥¼ JavaScript íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        clothing_df: ë‹¹ì‹œì¦Œì˜ë¥˜ DataFrame
        acc_df: ACC ì¬ê³ ì£¼ìˆ˜ DataFrame
        dates: ë‚ ì§œ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        output_path: ì €ì¥ ê²½ë¡œ
    """
    # ë””ë ‰í† ë¦¬ ìƒì„±
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ë‹¹ì‹œì¦Œì˜ë¥˜ ë°ì´í„° ë³€í™˜
    clothing_data = {}
    for _, row in clothing_df.iterrows():
        brand = row['ë¸Œëœë“œ']
        if brand not in clothing_data:
            clothing_data[brand] = []
        
        item_data = {
            'category': row['ëŒ€ë¶„ë¥˜'],
            'subCategory': row['ì¤‘ë¶„ë¥˜'],
            'itemCode': row['ì•„ì´í…œì½”ë“œ'],
            'itemName': row['ì•„ì´í…œëª…(í•œê¸€)'],
            'orderTag': float(row['ë°œì£¼(TAG)']) if pd.notna(row['ë°œì£¼(TAG)']) else 0,
            'orderYoY': float(row['ì „ë…„ë¹„(ë°œì£¼)']) if pd.notna(row['ì „ë…„ë¹„(ë°œì£¼)']) else None,
            'weeklySalesTag': float(row['ì£¼ê°„íŒë§¤ë§¤ì¶œ(TAG)']) if pd.notna(row['ì£¼ê°„íŒë§¤ë§¤ì¶œ(TAG)']) else 0,
            'weeklyYoY': float(row['ì „ë…„ë¹„(ì£¼ê°„)']) if pd.notna(row['ì „ë…„ë¹„(ì£¼ê°„)']) else None,
            'cumSalesTag': float(row['ëˆ„ì íŒë§¤ë§¤ì¶œ(TAG)']) if pd.notna(row['ëˆ„ì íŒë§¤ë§¤ì¶œ(TAG)']) else 0,
            'cumYoY': float(row['ì „ë…„ë¹„(ëˆ„ì )']) if pd.notna(row['ì „ë…„ë¹„(ëˆ„ì )']) else None,
            'cumSalesRate': float(row['ëˆ„ì íŒë§¤ìœ¨ë‹¹ë…„']) if pd.notna(row['ëˆ„ì íŒë§¤ìœ¨ë‹¹ë…„']) else None,
            'cumSalesRateDiff': float(row['ëˆ„ì íŒë§¤ìœ¨ì°¨ì´']) if pd.notna(row['ëˆ„ì íŒë§¤ìœ¨ì°¨ì´']) else None,
            'pyClosingSalesRate': float(row['ì „ë…„ë§ˆê°íŒë§¤ìœ¨']) if pd.notna(row['ì „ë…„ë§ˆê°íŒë§¤ìœ¨']) else None
        }
        clothing_data[brand].append(item_data)
    
    # ACC ì¬ê³ ì£¼ìˆ˜ ë°ì´í„° ë³€í™˜
    acc_data = {}
    for _, row in acc_df.iterrows():
        brand = row['ë¸Œëœë“œì½”ë“œ']
        if brand not in acc_data:
            acc_data[brand] = []
        
        item_data = {
            'category': row['ì¹´í…Œê³ ë¦¬'],
            'itemCode': row['ì•„ì´í…œ'],
            'itemName': row['ì•„ì´í…œëª…'],
            'saleQty': int(row['íŒë§¤ìˆ˜ëŸ‰']) if pd.notna(row['íŒë§¤ìˆ˜ëŸ‰']) else 0,
            'saleAmt': int(row['íŒë§¤ë§¤ì¶œ']) if pd.notna(row['íŒë§¤ë§¤ì¶œ']) else 0,
            'yoyRate': row['ì „ë…„ë¹„'] if pd.notna(row['ì „ë…„ë¹„']) else None,
            'shareRate': row['ë¹„ì¤‘'] if pd.notna(row['ë¹„ì¤‘']) else '0%',
            'avg4wSaleQty': float(row['4ì£¼í‰ê· íŒë§¤ëŸ‰']) if pd.notna(row['4ì£¼í‰ê· íŒë§¤ëŸ‰']) else 0,
            'stockQty': int(row['ì¬ê³ ']) if pd.notna(row['ì¬ê³ ']) else 0,
            'stockAmt': int(float(row['ì¬ê³ ê¸ˆì•¡'])) if pd.notna(row.get('ì¬ê³ ê¸ˆì•¡', 0)) and row.get('ì¬ê³ ê¸ˆì•¡', 0) != 0 else 0,
            'stockWeeks': float(row['ì¬ê³ ì£¼ìˆ˜']) if pd.notna(row['ì¬ê³ ì£¼ìˆ˜']) else None,
            'pyStockWeeks': float(row['ì „ë…„ì¬ê³ ì£¼ìˆ˜']) if pd.notna(row['ì „ë…„ì¬ê³ ì£¼ìˆ˜']) else None,
            'stockWeeksDiff': float(row['ì¬ê³ ì£¼ìˆ˜ì°¨ì´(ë‹¹ë…„-ì „ë…„)']) if pd.notna(row['ì¬ê³ ì£¼ìˆ˜ì°¨ì´(ë‹¹ë…„-ì „ë…„)']) else None
        }
        acc_data[brand].append(item_data)
    
    # ë©”íƒ€ë°ì´í„°
    metadata = {
        'updateDate': dates['update_date'].strftime('%Y-%m-%d'),
        'cyWeekStart': dates['cy_week_start'].strftime('%Y-%m-%d'),
        'cyWeekEnd': dates['cy_week_end'].strftime('%Y-%m-%d'),
        'pyWeekStart': dates['py_week_start'].strftime('%Y-%m-%d'),
        'pyWeekEnd': dates['py_week_end'].strftime('%Y-%m-%d'),
        'cySeason': dates['cy_season'],
        'pySeason': dates['py_season'],
        'pySeasonEnd': dates['py_season_end'].strftime('%Y-%m-%d'),
        'generatedAt': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # JavaScript íŒŒì¼ ìƒì„±
    js_content = f"""// ë¸Œëœë“œë³„ í˜„í™© - ë‹¹ì‹œì¦Œì˜ë¥˜/ACC ì¬ê³ ì£¼ìˆ˜ ë¶„ì„ ë°ì´í„°
// ìë™ ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
// ì—…ë°ì´íŠ¸ ì¼ì: {dates['update_date'].strftime('%Y-%m-%d')}
// ë‹¹ë…„ ì£¼ê°„: {dates['cy_week_start'].strftime('%Y-%m-%d')} ~ {dates['cy_week_end'].strftime('%Y-%m-%d')}
// ì „ë…„ ë™ì£¼ì°¨: {dates['py_week_start'].strftime('%Y-%m-%d')} ~ {dates['py_week_end'].strftime('%Y-%m-%d')}

(function() {{
  // ë©”íƒ€ë°ì´í„°
  var brandStockMetadata = {json.dumps(metadata, ensure_ascii=False, indent=2)};
  
  // ë‹¹ì‹œì¦Œì˜ë¥˜ ë¸Œëœë“œë³„ í˜„í™© (ACC ì œì™¸)
  var clothingBrandStatus = {json.dumps(clothing_data, ensure_ascii=False, indent=2)};
  
  // ACC ì¬ê³ ì£¼ìˆ˜ ë¶„ì„
  var accStockAnalysis = {json.dumps(acc_data, ensure_ascii=False, indent=2)};
  
  // ë¸Œëœë“œë³„ ìš”ì•½ í†µê³„ (ë‹¹ì‹œì¦Œì˜ë¥˜)
  var clothingSummary = {{}};
  for (var brand in clothingBrandStatus) {{
    var items = clothingBrandStatus[brand];
    clothingSummary[brand] = {{
      itemCount: items.length,
      totalOrderTag: items.reduce(function(sum, item) {{ return sum + (item.orderTag || 0); }}, 0),
      totalWeeklySales: items.reduce(function(sum, item) {{ return sum + (item.weeklySalesTag || 0); }}, 0),
      totalCumSales: items.reduce(function(sum, item) {{ return sum + (item.cumSalesTag || 0); }}, 0)
    }};
  }}
  
  // ë¸Œëœë“œë³„ ìš”ì•½ í†µê³„ (ACC)
  var accSummary = {{}};
  for (var brand in accStockAnalysis) {{
    var items = accStockAnalysis[brand];
    accSummary[brand] = {{
      itemCount: items.length,
      totalSaleQty: items.reduce(function(sum, item) {{ return sum + (item.saleQty || 0); }}, 0),
      totalSaleAmt: items.reduce(function(sum, item) {{ return sum + (item.saleAmt || 0); }}, 0),
      totalStockQty: items.reduce(function(sum, item) {{ return sum + (item.stockQty || 0); }}, 0)
    }};
  }}
  
  // ì „ì—­ ê°ì²´ì— í• ë‹¹
  if (typeof window !== 'undefined') {{
    window.brandStockMetadata = brandStockMetadata;
    window.clothingBrandStatus = clothingBrandStatus;
    window.accStockAnalysis = accStockAnalysis;
    window.clothingSummary = clothingSummary;
    window.accSummary = accSummary;
  }}
}})();
"""
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(js_content)
    
    file_size = output_path.stat().st_size / 1024
    print(f"   [ì™„ë£Œ] JS íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"   [íŒŒì¼í¬ê¸°] íŒŒì¼ í¬ê¸°: {file_size:.2f} KB")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë¸Œëœë“œë³„ í˜„í™© - ë‹¹ì‹œì¦Œì˜ë¥˜/ACC ì¬ê³ ì£¼ìˆ˜ ë¶„ì„ ë‹¤ìš´ë¡œë“œ')
    parser.add_argument('--update-date', '-d', type=str, 
                        help='ì—…ë°ì´íŠ¸ ì¼ì (YYYY-MM-DD í˜•ì‹, ê¸°ë³¸ê°’: ì˜¤ëŠ˜)')
    parser.add_argument('--output-dir', '-o', type=str,
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: raw/YYYYMM/ETC)')
    parser.add_argument('--no-js', action='store_true',
                        help='JS íŒŒì¼ ìƒì„± ì•ˆ í•¨')
    args = parser.parse_args()
    
    # ì—…ë°ì´íŠ¸ ì¼ì ì„¤ì •
    if args.update_date:
        try:
            update_date = datetime.strptime(args.update_date, '%Y-%m-%d')
        except ValueError:
            print(f"[ì˜¤ë¥˜] ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {args.update_date}")
            print("   ì˜¬ë°”ë¥¸ í˜•ì‹: YYYY-MM-DD (ì˜ˆ: 2025-11-24)")
            sys.exit(1)
    else:
        update_date = datetime.now()
    
    # ë‚ ì§œ ê³„ì‚°
    dates = calculate_dates(update_date)
    
    print("=" * 60)
    print("[ë¸Œëœë“œë³„ í˜„í™©] ë‹¹ì‹œì¦Œì˜ë¥˜/ACC ì¬ê³ ì£¼ìˆ˜ ë¶„ì„")
    print("=" * 60)
    print(f"\n[ë‚ ì§œ ì„¤ì •]")
    print(f"   ì—…ë°ì´íŠ¸ ì¼ì: {dates['update_date'].strftime('%Y-%m-%d')}")
    print(f"   ë‹¹ë…„ ì£¼ê°„: {dates['cy_week_start'].strftime('%Y-%m-%d')} ~ {dates['cy_week_end'].strftime('%Y-%m-%d')}")
    print(f"   ì „ë…„ ë™ì£¼ì°¨: {dates['py_week_start'].strftime('%Y-%m-%d')} ~ {dates['py_week_end'].strftime('%Y-%m-%d')}")
    print(f"   ë‹¹ë…„ ì‹œì¦Œ: {dates['cy_season']}")
    print(f"   ì „ë…„ ì‹œì¦Œ: {dates['py_season']}")
    print(f"   ì „ë…„ ì‹œì¦Œ ë§ˆê°: {dates['py_season_end'].strftime('%Y-%m-%d')}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • (í‰ê°€ì›” ì‚¬ìš©)
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        # ì—…ë°ì´íŠ¸ ë‚ ì§œë¥¼ YYYYMMDD í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        date_str = update_date.strftime('%Y%m%d')
        # í‰ê°€ì›”(analysis_month) ì¶”ì¶œ (metadata.jsonì—ì„œ ì½ê±°ë‚˜ ê³„ì‚°)
        from scripts.path_utils import extract_year_month_from_date
        year_month = extract_year_month_from_date(date_str)
        output_dir = project_root / 'raw' / year_month / 'ETC'
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    # íŒŒì¼ëª… ì„¤ì •
    date_suffix = update_date.strftime('%Y%m%d')
    clothing_file = output_dir / f"ë‹¹ì‹œì¦Œì˜ë¥˜_ë¸Œëœë“œë³„í˜„í™©_{date_suffix}.csv"
    acc_file = output_dir / f"ACC_ì¬ê³ ì£¼ìˆ˜ë¶„ì„_{date_suffix}.csv"
    
    conn = None
    try:
        # Snowflake ì—°ê²°
        conn = get_snowflake_connection()
        
        # 1. ë‹¹ì‹œì¦Œì˜ë¥˜ ë¶„ì„
        print(f"\n[ì§„í–‰] ë‹¹ì‹œì¦Œì˜ë¥˜ ë¶„ì„ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
        clothing_query = build_clothing_query(dates)
        clothing_df = execute_query(conn, clothing_query)
        clothing_df.to_csv(clothing_file, index=False, encoding='utf-8-sig')
        print(f"   [ì™„ë£Œ] ì €ì¥ ì™„ë£Œ: {clothing_file}")
        print(f"   [ë°ì´í„°] ë°ì´í„° ê±´ìˆ˜: {len(clothing_df):,}ê±´")
        
        # 2. ACC ì¬ê³ ì£¼ìˆ˜ ë¶„ì„
        print(f"\n[ì§„í–‰] ACC ì¬ê³ ì£¼ìˆ˜ ë¶„ì„ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
        acc_query = build_acc_stock_query(dates)
        acc_df = execute_query(conn, acc_query)
        acc_df.to_csv(acc_file, index=False, encoding='utf-8-sig')
        print(f"   [ì™„ë£Œ] ì €ì¥ ì™„ë£Œ: {acc_file}")
        print(f"   [ë°ì´í„°] ë°ì´í„° ê±´ìˆ˜: {len(acc_df):,}ê±´")
        
        # 3. JS íŒŒì¼ ìƒì„± (ì˜µì…˜)
        if not args.no_js:
            print(f"\n[ì§„í–‰] JS íŒŒì¼ ìƒì„± ì¤‘...")
            js_output_path = project_root / 'public' / f'brand_stock_analysis_{date_suffix}.js'
            save_to_js(clothing_df, acc_df, dates, js_output_path)
        
        print("\n" + "=" * 60)
        print("[ì™„ë£Œ] ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("=" * 60)
        
        print(f"\n[ìƒì„±ëœ íŒŒì¼]")
        print(f"   - {clothing_file}")
        print(f"   - {acc_file}")
        if not args.no_js:
            print(f"   - {js_output_path}")
        
        # â˜…â˜…â˜… JSON íŒŒì¼ë¡œë„ ì €ì¥ â˜…â˜…â˜…
        json_dir = project_root / 'public' / 'data' / date_suffix
        json_dir.mkdir(parents=True, exist_ok=True)
        
        # dates ë”•ì…”ë„ˆë¦¬ì˜ datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        dates_for_json = {
            'update_date': dates['update_date'].strftime('%Y-%m-%d') if isinstance(dates.get('update_date'), datetime) else dates.get('update_date'),
            'cy_week_start': dates['cy_week_start'].strftime('%Y-%m-%d') if isinstance(dates.get('cy_week_start'), datetime) else dates.get('cy_week_start'),
            'cy_week_end': dates['cy_week_end'].strftime('%Y-%m-%d') if isinstance(dates.get('cy_week_end'), datetime) else dates.get('cy_week_end'),
            'py_week_start': dates['py_week_start'].strftime('%Y-%m-%d') if isinstance(dates.get('py_week_start'), datetime) else dates.get('py_week_start'),
            'py_week_end': dates['py_week_end'].strftime('%Y-%m-%d') if isinstance(dates.get('py_week_end'), datetime) else dates.get('py_week_end'),
            'cy_season': dates.get('cy_season'),
            'py_season': dates.get('py_season'),
            'py_season_end': dates['py_season_end'].strftime('%Y-%m-%d') if isinstance(dates.get('py_season_end'), datetime) else dates.get('py_season_end'),
            'cy_4w_start': dates['cy_4w_start'].strftime('%Y-%m-%d') if isinstance(dates.get('cy_4w_start'), datetime) else dates.get('cy_4w_start'),
            'py_4w_start': dates['py_4w_start'].strftime('%Y-%m-%d') if isinstance(dates.get('py_4w_start'), datetime) else dates.get('py_4w_start'),
        }
        
        # DataFrameì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (Decimal íƒ€ì… ì²˜ë¦¬)
        def convert_decimal_to_float(obj):
            """Decimal íƒ€ì…ì„ floatë¡œ ë³€í™˜í•˜ëŠ” ì¬ê·€ í•¨ìˆ˜"""
            if isinstance(obj, Decimal):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_decimal_to_float(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_decimal_to_float(item) for item in obj]
            elif isinstance(obj, (int, float, str, bool, type(None))):
                return obj
            else:
                # ë‹¤ë¥¸ íƒ€ì…ë„ ì‹œë„
                try:
                    return float(obj)
                except (ValueError, TypeError):
                    return str(obj)
        
        # ì˜ë¥˜ ë° ACC ë°ì´í„°ë¥¼ ë¸Œëœë“œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ JSONìœ¼ë¡œ ë³€í™˜ (generate_brand_stock_analysis.pyì™€ ë™ì¼í•œ êµ¬ì¡°)
        clothing_by_brand = {}
        if not clothing_df.empty:
            print(f"\n[ì˜ë¥˜ ë°ì´í„° ë³€í™˜] ì´ {len(clothing_df)}ê±´")
            print(f"[ì˜ë¥˜ ë°ì´í„° ë³€í™˜] ì»¬ëŸ¼: {list(clothing_df.columns)}")
            
            # ë¸Œëœë“œ ì»¬ëŸ¼ëª… í™•ì¸ (í•œê¸€ ë˜ëŠ” ì˜ë¬¸)
            brand_col = None
            for col in ['ë¸Œëœë“œ', 'brand', 'BRAND', 'ë¸Œëœë“œì½”ë“œ']:
                if col in clothing_df.columns:
                    brand_col = col
                    print(f"[ì˜ë¥˜ ë°ì´í„° ë³€í™˜] ë¸Œëœë“œ ì»¬ëŸ¼ ë°œê²¬: {brand_col}")
                    break
            
            if brand_col:
                unique_brands = clothing_df[brand_col].unique()
                print(f"[ì˜ë¥˜ ë°ì´í„° ë³€í™˜] ë¸Œëœë“œ ëª©ë¡: {list(unique_brands)}")
                
                for brand_code in unique_brands:
                    brand_code_str = str(brand_code).strip()
                    brand_df = clothing_df[clothing_df[brand_col] == brand_code]
                    
                    # generate_brand_stock_analysis.pyì™€ ë™ì¼í•œ í•„ë“œëª… êµ¬ì¡°ë¡œ ë³€í™˜
                    brand_items = []
                    for _, row in brand_df.iterrows():
                        item_data = {
                            "category": str(row.get('ëŒ€ë¶„ë¥˜', '')).strip() if pd.notna(row.get('ëŒ€ë¶„ë¥˜')) else "",
                            "subCategory": str(row.get('ì¤‘ë¶„ë¥˜', '')).strip() if pd.notna(row.get('ì¤‘ë¶„ë¥˜')) else "",
                            "itemCode": str(row.get('ì•„ì´í…œì½”ë“œ', '')).strip() if pd.notna(row.get('ì•„ì´í…œì½”ë“œ')) else "",
                            "itemName": str(row.get('ì•„ì´í…œëª…(í•œê¸€)', '')).strip() if pd.notna(row.get('ì•„ì´í…œëª…(í•œê¸€)')) else "",
                            "orderTag": convert_decimal_to_float(row.get('ë°œì£¼(TAG)', 0)) if pd.notna(row.get('ë°œì£¼(TAG)', 0)) else None,
                            "orderYoY": convert_decimal_to_float(row.get('ì „ë…„ë¹„(ë°œì£¼)', None)) if pd.notna(row.get('ì „ë…„ë¹„(ë°œì£¼)', None)) else None,
                            "weeklySalesTag": convert_decimal_to_float(row.get('ì£¼ê°„íŒë§¤ë§¤ì¶œ(TAG)', 0)) if pd.notna(row.get('ì£¼ê°„íŒë§¤ë§¤ì¶œ(TAG)', 0)) else None,
                            "weeklyYoY": convert_decimal_to_float(row.get('ì „ë…„ë¹„(ì£¼ê°„)', None)) if pd.notna(row.get('ì „ë…„ë¹„(ì£¼ê°„)', None)) else None,
                            "cumSalesTag": convert_decimal_to_float(row.get('ëˆ„ì íŒë§¤ë§¤ì¶œ(TAG)', 0)) if pd.notna(row.get('ëˆ„ì íŒë§¤ë§¤ì¶œ(TAG)', 0)) else None,
                            "cumYoY": convert_decimal_to_float(row.get('ì „ë…„ë¹„(ëˆ„ì )', None)) if pd.notna(row.get('ì „ë…„ë¹„(ëˆ„ì )', None)) else None,
                            "cumSalesRate": convert_decimal_to_float(row.get('ëˆ„ì íŒë§¤ìœ¨ë‹¹ë…„', None)) if pd.notna(row.get('ëˆ„ì íŒë§¤ìœ¨ë‹¹ë…„', None)) else None,
                            "cumSalesRateDiff": convert_decimal_to_float(row.get('ëˆ„ì íŒë§¤ìœ¨ì°¨ì´', None)) if pd.notna(row.get('ëˆ„ì íŒë§¤ìœ¨ì°¨ì´', None)) else None,
                            "pyClosingSalesRate": convert_decimal_to_float(row.get('ì „ë…„ë§ˆê°íŒë§¤ìœ¨', None)) if pd.notna(row.get('ì „ë…„ë§ˆê°íŒë§¤ìœ¨', None)) else None
                        }
                        brand_items.append(item_data)
                    
                    clothing_by_brand[brand_code_str] = brand_items
                    print(f"[ì˜ë¥˜ ë°ì´í„° ë³€í™˜] ë¸Œëœë“œ {brand_code_str}: {len(brand_items)}ê±´")
            else:
                print(f"[ì˜ë¥˜ ë°ì´í„° ë³€í™˜] âš ï¸ ë¸Œëœë“œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                print(f"[ì˜ë¥˜ ë°ì´í„° ë³€í™˜] ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(clothing_df.columns)}")
        
        acc_by_brand = {}
        if not acc_df.empty:
            print(f"\n[ACC ë°ì´í„° ë³€í™˜] ì´ {len(acc_df)}ê±´")
            print(f"[ACC ë°ì´í„° ë³€í™˜] ì»¬ëŸ¼: {list(acc_df.columns)}")
            
            # ë¸Œëœë“œ ì»¬ëŸ¼ëª… í™•ì¸
            brand_col = None
            for col in ['ë¸Œëœë“œì½”ë“œ', 'brand', 'BRAND', 'ë¸Œëœë“œ']:
                if col in acc_df.columns:
                    brand_col = col
                    print(f"[ACC ë°ì´í„° ë³€í™˜] ë¸Œëœë“œ ì»¬ëŸ¼ ë°œê²¬: {brand_col}")
                    break
            
            if brand_col:
                unique_brands = acc_df[brand_col].unique()
                print(f"[ACC ë°ì´í„° ë³€í™˜] ë¸Œëœë“œ ëª©ë¡: {list(unique_brands)}")
                
                for brand_code in unique_brands:
                    brand_code_str = str(brand_code).strip()
                    brand_df = acc_df[acc_df[brand_col] == brand_code]
                    
                    # generate_brand_stock_analysis.pyì™€ ë™ì¼í•œ í•„ë“œëª… êµ¬ì¡°ë¡œ ë³€í™˜
                    brand_items = []
                    for _, row in brand_df.iterrows():
                        # ì „ë…„ë¹„ì™€ ë¹„ì¤‘ì€ í¼ì„¼íŠ¸ ë¬¸ìì—´ë¡œ ìœ ì§€
                        yoy_rate = row.get('ì „ë…„ë¹„', None)
                        if pd.notna(yoy_rate) and yoy_rate != '':
                            yoy_rate_str = str(yoy_rate).strip()
                            if not yoy_rate_str.endswith('%'):
                                try:
                                    yoy_rate_str = f"{int(float(yoy_rate_str))}%"
                                except:
                                    pass
                        else:
                            yoy_rate_str = None
                        
                        share_rate = row.get('ë¹„ì¤‘', '0%')
                        if pd.notna(share_rate) and share_rate != '':
                            share_rate_str = str(share_rate).strip()
                        else:
                            share_rate_str = "0%"
                        
                        item_data = {
                            "category": str(row.get('ì¹´í…Œê³ ë¦¬', '')).strip() if pd.notna(row.get('ì¹´í…Œê³ ë¦¬')) else "",
                            "itemCode": str(row.get('ì•„ì´í…œ', '')).strip() if pd.notna(row.get('ì•„ì´í…œ')) else "",
                            "itemName": str(row.get('ì•„ì´í…œëª…', '')).strip() if pd.notna(row.get('ì•„ì´í…œëª…')) else "",
                            "saleQty": int(convert_decimal_to_float(row.get('íŒë§¤ìˆ˜ëŸ‰', 0))) if pd.notna(row.get('íŒë§¤ìˆ˜ëŸ‰', 0)) else None,
                            "saleAmt": int(convert_decimal_to_float(row.get('íŒë§¤ë§¤ì¶œ', 0))) if pd.notna(row.get('íŒë§¤ë§¤ì¶œ', 0)) else None,
                            "yoyRate": yoy_rate_str,
                            "shareRate": share_rate_str,
                            "avg4wSaleQty": convert_decimal_to_float(row.get('4ì£¼í‰ê· íŒë§¤ëŸ‰', None)) if pd.notna(row.get('4ì£¼í‰ê· íŒë§¤ëŸ‰', None)) else None,
                            "stockQty": int(convert_decimal_to_float(row.get('ì¬ê³ ', 0))) if pd.notna(row.get('ì¬ê³ ', 0)) else None,
                            "stockAmt": int(convert_decimal_to_float(row.get('ì¬ê³ ê¸ˆì•¡', 0))) if pd.notna(row.get('ì¬ê³ ê¸ˆì•¡', 0)) else 0,
                            "stockWeeks": convert_decimal_to_float(row.get('ì¬ê³ ì£¼ìˆ˜', None)) if pd.notna(row.get('ì¬ê³ ì£¼ìˆ˜', None)) else None,
                            "pyStockWeeks": convert_decimal_to_float(row.get('ì „ë…„ì¬ê³ ì£¼ìˆ˜', None)) if pd.notna(row.get('ì „ë…„ì¬ê³ ì£¼ìˆ˜', None)) else None,
                            "stockWeeksDiff": convert_decimal_to_float(row.get('ì¬ê³ ì£¼ìˆ˜ì°¨ì´(ë‹¹ë…„-ì „ë…„)', None)) if pd.notna(row.get('ì¬ê³ ì£¼ìˆ˜ì°¨ì´(ë‹¹ë…„-ì „ë…„)', None)) else None
                        }
                        brand_items.append(item_data)
                    
                    acc_by_brand[brand_code_str] = brand_items
                    print(f"[ACC ë°ì´í„° ë³€í™˜] ë¸Œëœë“œ {brand_code_str}: {len(brand_items)}ê±´")
            else:
                print(f"[ACC ë°ì´í„° ë³€í™˜] âš ï¸ ë¸Œëœë“œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                print(f"[ACC ë°ì´í„° ë³€í™˜] ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(acc_df.columns)}")
        
        # ë¸Œëœë“œë³„ ìš”ì•½ í†µê³„ ê³„ì‚° (ë‹¹ì‹œì¦Œì˜ë¥˜)
        clothing_summary = {}
        for brand, items in clothing_by_brand.items():
            clothing_summary[brand] = {
                "itemCount": len(items),
                "totalOrderTag": sum(item.get("orderTag", 0) or 0 for item in items),
                "totalWeeklySales": sum(item.get("weeklySalesTag", 0) or 0 for item in items),
                "totalCumSales": sum(item.get("cumSalesTag", 0) or 0 for item in items)
            }
        
        # ë¸Œëœë“œë³„ ìš”ì•½ í†µê³„ ê³„ì‚° (ACC)
        acc_summary = {}
        for brand, items in acc_by_brand.items():
            acc_summary[brand] = {
                "itemCount": len(items),
                "totalSaleQty": sum(item.get("saleQty", 0) or 0 for item in items),
                "totalSaleAmt": sum(item.get("saleAmt", 0) or 0 for item in items),
                "totalStockQty": sum(item.get("stockQty", 0) or 0 for item in items),
                "totalStockAmt": sum(item.get("stockAmt", 0) or 0 for item in items)
            }
        
        stock_data = {
            'brandStockMetadata': dates_for_json,
            'clothingBrandStatus': clothing_by_brand,
            'accStockAnalysis': acc_by_brand,
            'clothingSummary': clothing_summary,
            'accSummary': acc_summary
        }
        
        json_path = json_dir / "stock_analysis.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(stock_data, f, ensure_ascii=False, indent=2)
        
        print(f"\n  [ì™„ë£Œ] JSON ì €ì¥: {json_path}")
        print(f"  [ë°ì´í„°] ì˜ë¥˜ ë¸Œëœë“œ ìˆ˜: {len(clothing_by_brand)}")
        print(f"  [ë°ì´í„°] ACC ë¸Œëœë“œ ìˆ˜: {len(acc_by_brand)}")
        if clothing_by_brand:
            total_clothing_items = sum(len(items) for items in clothing_by_brand.values())
            print(f"  [ë°ì´í„°] ì˜ë¥˜ ì´ ì•„ì´í…œ ìˆ˜: {total_clothing_items}")
        if acc_by_brand:
            total_acc_items = sum(len(items) for items in acc_by_brand.values())
            print(f"  [ë°ì´í„°] ACC ì´ ì•„ì´í…œ ìˆ˜: {total_acc_items}")
        
    except Exception as e:
        print(f"\n[ì˜¤ë¥˜] ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        if conn:
            conn.close()
            print("\n[ì—°ê²°ì¢…ë£Œ] Snowflake ì—°ê²° ì¢…ë£Œ")


if __name__ == "__main__":
    main()

