"""
íŠ¸ë¦¬ë§µ ë°ì´í„° ì •ì œ ìŠ¤í¬ë¦½íŠ¸
=================================

ì‘ì—… íë¦„:
1. ì „ì²˜ë¦¬ ì™„ë£Œëœ CSV íŒŒì¼ ì½ê¸°
2. ë¸Œëœë“œ, ì±„ë„ëª…, ì•„ì´í…œë¶„ë¥˜ë³„ ì§‘ê³„
3. JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (Dashboard.html í˜•ì‹ì— ë§ê²Œ)
4. public/treemap_data.js íŒŒì¼ ìƒì„±

ì‘ì„±ì¼: 2025-11-14
"""

import pandas as pd
import json
import os
from datetime import datetime
import sys

# ================================
# ì„¤ì • (Configuration)
# ================================

# ê²½ë¡œ ì„¤ì •
INPUT_DIR = r"C:\Users\AD0283\Desktop\AIproject\Project_Forcast\raw"
OUTPUT_DIR = r"C:\Users\AD0283\Desktop\AIproject\Project_Forcast\public"

# ì…ë ¥ íŒŒì¼ íŒ¨í„´ (ì „ì²˜ë¦¬ì™„ë£Œ íŒŒì¼)
INPUT_FILE_PATTERN = "_ì „ì²˜ë¦¬ì™„ë£Œ.csv"

# ì¶œë ¥ íŒŒì¼ëª…
OUTPUT_JS_FILE = "treemap_data.js"

# ================================
# ë¸Œëœë“œ ì½”ë“œ ë§¤í•‘
# ================================

BRAND_CODE_MAP = {
    'M': 'M',           # MLB
    'MLB': 'M',
    'I': 'I',           # MLB KIDS
    'MLB KIDS': 'I',
    'MLB_KIDS': 'I',
    'X': 'X',           # DISCOVERY
    'DISCOVERY': 'X',
    'V': 'V',           # DUVETICA
    'DUVETICA': 'V',
    'ST': 'ST',         # SERGIO
    'SERGIO': 'ST',
    'W': 'W',           # SUPRA
    'SUPRA': 'W'
}

# ë¸Œëœë“œ ì´ë¦„ ë§¤í•‘
BRAND_NAME_MAP = {
    'M': 'MLB',
    'I': 'MLB KIDS',
    'X': 'DISCOVERY',
    'V': 'DUVETICA',
    'ST': 'SERGIO',
    'W': 'SUPRA'
}

# ================================
# í•¨ìˆ˜ ì •ì˜
# ================================

def find_latest_processed_file():
    """
    raw í´ë”ì—ì„œ ìµœì‹  ì „ì²˜ë¦¬ì™„ë£Œ CSV íŒŒì¼ ì°¾ê¸°
    
    Returns:
        str: íŒŒì¼ ì „ì²´ ê²½ë¡œ
    """
    if not os.path.exists(INPUT_DIR):
        raise FileNotFoundError(f"âŒ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {INPUT_DIR}")
    
    # _ì „ì²˜ë¦¬ì™„ë£Œ.csvë¡œ ëë‚˜ëŠ” ëª¨ë“  íŒŒì¼ ì°¾ê¸°
    files = []
    for filename in os.listdir(INPUT_DIR):
        if filename.endswith(INPUT_FILE_PATTERN):
            filepath = os.path.join(INPUT_DIR, filename)
            mtime = os.path.getmtime(filepath)
            files.append((filepath, mtime, filename))
    
    if not files:
        raise FileNotFoundError(f"âŒ {INPUT_DIR} í´ë”ì— ì „ì²˜ë¦¬ì™„ë£Œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    # ìµœì‹  íŒŒì¼ ì„ íƒ (ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
    latest_file = sorted(files, key=lambda x: x[1], reverse=True)[0]
    print(f"âœ… ìµœì‹  íŒŒì¼ ë°œê²¬: {latest_file[2]}")
    
    return latest_file[0]


def load_and_aggregate_data(csv_path):
    """
    CSV íŒŒì¼ì„ ì½ê³  ë¸Œëœë“œ, ì±„ë„ëª…, ì•„ì´í…œë¶„ë¥˜ë³„ ì§‘ê³„
    
    Args:
        csv_path (str): ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
    
    Returns:
        pd.DataFrame: ì§‘ê³„ëœ ë°ì´í„°
    """
    print(f"\nğŸ“¥ CSV íŒŒì¼ ì½ëŠ” ì¤‘: {csv_path}")
    
    # CSV ì½ê¸°
    df = pd.read_csv(csv_path, encoding='utf-8-sig')
    print(f"   ì›ë³¸ ë°ì´í„°: {len(df)}í–‰ Ã— {len(df.columns)}ì—´")
    
    # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['ë¸Œëœë“œ', 'ìœ í†µì±„ë„', 'PH01-3']
    value_cols_candidates = [
        'í•©ê³„ : íŒë§¤ê¸ˆì•¡(TAGê°€) Actual',
        'íŒë§¤ê¸ˆì•¡(TAGê°€) Actual',
        'íŒë§¤ê¸ˆì•¡(TAGê°€)',
        'í•©ê³„ : ì‹¤íŒë§¤ì•¡ Actual',
        'ì‹¤íŒë§¤ì•¡ Actual',
        'ì‹¤íŒë§¤ì•¡'
    ]
    
    # ì»¬ëŸ¼ëª… ìœ ì—°í•œ ë§¤ì¹­
    column_map = {}
    for req_col in required_cols:
        found = False
        for col in df.columns:
            if req_col in str(col) or str(col) in req_col:
                column_map[col] = req_col
                found = True
                break
        if not found:
            print(f"âš ï¸  '{req_col}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # ê°’ ì»¬ëŸ¼ ì°¾ê¸°
    tag_col = None
    sales_col = None
    
    for candidate in value_cols_candidates[:3]:  # TAGê°€ ë¨¼ì €
        for col in df.columns:
            if candidate in str(col):
                tag_col = col
                break
        if tag_col:
            break
    
    for candidate in value_cols_candidates[3:]:  # ì‹¤íŒë§¤ì•¡
        for col in df.columns:
            if candidate in str(col):
                sales_col = col
                break
        if sales_col:
            break
    
    if not tag_col:
        print(f"âš ï¸  'íŒë§¤ê¸ˆì•¡(TAGê°€)' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
        raise ValueError("í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: íŒë§¤ê¸ˆì•¡(TAGê°€)")
    
    if not sales_col:
        print(f"âš ï¸  'ì‹¤íŒë§¤ì•¡' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        sales_col = tag_col  # í´ë°±: TAGê°€ ì‚¬ìš©
    
    print(f"   TAGê°€ ì»¬ëŸ¼: {tag_col}")
    print(f"   ì‹¤íŒë§¤ì•¡ ì»¬ëŸ¼: {sales_col}")
    
    # ì»¬ëŸ¼ëª… í‘œì¤€í™”
    df = df.rename(columns=column_map)
    
    # ì§‘ê³„ ì»¬ëŸ¼ ì„¤ì •
    group_cols = []
    if 'ë¸Œëœë“œ' in df.columns:
        group_cols.append('ë¸Œëœë“œ')
    if 'ìœ í†µì±„ë„' in df.columns:
        group_cols.append('ìœ í†µì±„ë„')
    if 'PH01-3' in df.columns:
        group_cols.append('PH01-3')
    
    if len(group_cols) == 0:
        raise ValueError("âŒ ì§‘ê³„í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    print(f"   ì§‘ê³„ ê¸°ì¤€: {group_cols}")
    
    # ìˆ«ì íƒ€ì… ë³€í™˜
    df[tag_col] = pd.to_numeric(df[tag_col], errors='coerce').fillna(0)
    df[sales_col] = pd.to_numeric(df[sales_col], errors='coerce').fillna(0)
    
    # ì§‘ê³„
    agg_dict = {
        tag_col: 'sum',
        sales_col: 'sum'
    }
    
    df_agg = df.groupby(group_cols, as_index=False).agg(agg_dict)
    
    # ì»¬ëŸ¼ëª… ë‹¨ìˆœí™”
    df_agg = df_agg.rename(columns={
        tag_col: 'TAGê°€',
        sales_col: 'ì‹¤íŒë§¤ì•¡'
    })
    
    print(f"âœ… ì§‘ê³„ ì™„ë£Œ: {len(df_agg)}í–‰")
    print(f"   ì´ TAGê°€: {df_agg['TAGê°€'].sum():,.0f}")
    print(f"   ì´ ì‹¤íŒë§¤ì•¡: {df_agg['ì‹¤íŒë§¤ì•¡'].sum():,.0f}")
    
    return df_agg


def convert_to_treemap_json(df_agg):
    """
    ì§‘ê³„ëœ ë°ì´í„°ë¥¼ íŠ¸ë¦¬ë§µ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        df_agg (pd.DataFrame): ì§‘ê³„ëœ ë°ì´í„°
    
    Returns:
        dict: íŠ¸ë¦¬ë§µ ë°ì´í„° (ë¸Œëœë“œ ì½”ë“œë³„)
    """
    print(f"\nğŸ”„ íŠ¸ë¦¬ë§µ JSON ë³€í™˜ ì¤‘...")
    
    treemap_data = {}
    
    # ì»¬ëŸ¼ëª… í™•ì¸
    has_brand = 'ë¸Œëœë“œ' in df_agg.columns
    has_channel = 'ìœ í†µì±„ë„' in df_agg.columns
    has_item = 'PH01-3' in df_agg.columns
    
    if not (has_brand and has_channel and has_item):
        print(f"âš ï¸  í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½")
        print(f"   ë¸Œëœë“œ: {has_brand}, ìœ í†µì±„ë„: {has_channel}, PH01-3: {has_item}")
        return treemap_data
    
    # ë¸Œëœë“œë³„ë¡œ ê·¸ë£¹í™”
    for brand in df_agg['ë¸Œëœë“œ'].unique():
        brand_df = df_agg[df_agg['ë¸Œëœë“œ'] == brand].copy()
        
        # ë¸Œëœë“œ ì½”ë“œ ë³€í™˜
        brand_code = BRAND_CODE_MAP.get(str(brand).strip().upper(), str(brand).strip())
        
        if brand_code not in treemap_data:
            treemap_data[brand_code] = {}
        
        # ì±„ë„ë³„ë¡œ ê·¸ë£¹í™”
        for channel in brand_df['ìœ í†µì±„ë„'].unique():
            channel_df = brand_df[brand_df['ìœ í†µì±„ë„'] == channel]
            
            channel_name = str(channel).strip()
            if channel_name not in treemap_data[brand_code]:
                treemap_data[brand_code][channel_name] = {}
            
            # ì•„ì´í…œë³„ë¡œ ê·¸ë£¹í™”
            for item in channel_df['PH01-3'].unique():
                item_df = channel_df[channel_df['PH01-3'] == item]
                
                # ì‹¤íŒë§¤ì•¡ í•©ê³„ (ì› ë‹¨ìœ„)
                item_value = int(item_df['ì‹¤íŒë§¤ì•¡'].sum())
                
                item_name = str(item).strip()
                
                if item_value > 0:  # ì–‘ìˆ˜ì¸ ê²½ìš°ë§Œ ì¶”ê°€
                    treemap_data[brand_code][channel_name][item_name] = item_value
        
        print(f"   âœ… {brand} ({brand_code}): {len(treemap_data[brand_code])}ê°œ ì±„ë„")
    
    return treemap_data


def generate_js_file(treemap_data, output_path):
    """
    JavaScript íŒŒì¼ ìƒì„±
    
    Args:
        treemap_data (dict): íŠ¸ë¦¬ë§µ ë°ì´í„°
        output_path (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    print(f"\nğŸ“ JavaScript íŒŒì¼ ìƒì„± ì¤‘...")
    
    # JSON ë¬¸ìì—´ ìƒì„± (ë“¤ì—¬ì“°ê¸° í¬í•¨)
    json_str = json.dumps(treemap_data, indent=2, ensure_ascii=False)
    
    # JavaScript íŒŒì¼ ë‚´ìš© ìƒì„±
    js_content = f"""// íŠ¸ë¦¬ë§µ ë°ì´í„° (ìë™ ìƒì„±)
// ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
// í˜•ì‹: {{ 'ë¸Œëœë“œì½”ë“œ': {{ 'ì±„ë„ëª…': {{ 'ì•„ì´í…œëª…': ì‹¤íŒë§¤ì•¡(ì›) }} }} }}

window.channelItemSalesData = {json_str};

// ë¸Œëœë“œ ì½”ë“œ ë§¤í•‘
window.brandCodeMap = {{
  'MLB': 'M',
  'MLB KIDS': 'I',
  'MLB_KIDS': 'I',
  'DISCOVERY': 'X',
  'DUVETICA': 'V',
  'SERGIO': 'ST',
  'SUPRA': 'W',
  'M': 'M',
  'I': 'I',
  'X': 'X',
  'V': 'V',
  'ST': 'ST',
  'W': 'W'
}};

console.log('âœ… íŠ¸ë¦¬ë§µ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:', Object.keys(window.channelItemSalesData));
"""
    
    # íŒŒì¼ ì €ì¥
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(js_content)
    
    print(f"âœ… JavaScript íŒŒì¼ ì €ì¥: {output_path}")


def generate_summary_report(treemap_data):
    """
    ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        treemap_data (dict): íŠ¸ë¦¬ë§µ ë°ì´í„°
    """
    print(f"\n" + "=" * 60)
    print("ğŸ“Š íŠ¸ë¦¬ë§µ ë°ì´í„° ìš”ì•½")
    print("=" * 60)
    
    for brand_code, channels in treemap_data.items():
        brand_name = BRAND_NAME_MAP.get(brand_code, brand_code)
        total_sales = 0
        total_items = 0
        
        for channel_name, items in channels.items():
            channel_sales = sum(items.values())
            total_sales += channel_sales
            total_items += len(items)
        
        print(f"\nğŸ·ï¸  {brand_name} ({brand_code})")
        print(f"   ì±„ë„ ìˆ˜: {len(channels)}ê°œ")
        print(f"   ì•„ì´í…œ ìˆ˜: {total_items}ê°œ")
        print(f"   ì´ ë§¤ì¶œ: {total_sales:,.0f}ì› ({total_sales/100000000:.1f}ì–µì›)")
        
        # ì±„ë„ë³„ ìƒì„¸
        for channel_name, items in sorted(channels.items(), key=lambda x: sum(x[1].values()), reverse=True)[:5]:
            channel_sales = sum(items.values())
            print(f"     - {channel_name}: {channel_sales/100000000:.1f}ì–µì› ({len(items)}ê°œ ì•„ì´í…œ)")


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("=" * 60)
    print("íŠ¸ë¦¬ë§µ ë°ì´í„° ì •ì œ ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 60)
    print(f"ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    try:
        # ----------------
        # Step 1: ìµœì‹  ì „ì²˜ë¦¬ì™„ë£Œ íŒŒì¼ ì°¾ê¸°
        # ----------------
        csv_path = find_latest_processed_file()
        
        # ----------------
        # Step 2: ë°ì´í„° ë¡œë“œ ë° ì§‘ê³„
        # ----------------
        df_agg = load_and_aggregate_data(csv_path)
        
        # ----------------
        # Step 3: íŠ¸ë¦¬ë§µ JSON ë³€í™˜
        # ----------------
        treemap_data = convert_to_treemap_json(df_agg)
        
        # ----------------
        # Step 4: JavaScript íŒŒì¼ ìƒì„±
        # ----------------
        output_path = os.path.join(OUTPUT_DIR, OUTPUT_JS_FILE)
        generate_js_file(treemap_data, output_path)
        
        # ----------------
        # Step 5: ìš”ì•½ ë¦¬í¬íŠ¸
        # ----------------
        generate_summary_report(treemap_data)
        
        print(f"\nğŸ‰ ì™„ë£Œ!")
        print(f"   ìƒì„±ëœ íŒŒì¼: {output_path}")
        
        return treemap_data
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ================================
# ì§ì ‘ ì‹¤í–‰ ì‹œ
# ================================

if __name__ == "__main__":
    result = main()
    
    print(f"\nğŸ“‹ ë¸Œëœë“œë³„ ë°ì´í„° ê°œìˆ˜:")
    for brand_code, channels in result.items():
        brand_name = BRAND_NAME_MAP.get(brand_code, brand_code)
        channel_count = len(channels)
        item_count = sum(len(items) for items in channels.values())
        print(f"   {brand_name} ({brand_code}): {channel_count}ê°œ ì±„ë„, {item_count}ê°œ ì•„ì´í…œ")






