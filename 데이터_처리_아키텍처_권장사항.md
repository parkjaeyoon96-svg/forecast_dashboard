# 📊 데이터 처리 아키텍처 권장사항

## 🎯 현재 구조 분석

### 현재 데이터 흐름
```
로데이터 (Excel)
    ↓
[process_ke30_current_year.py]
    ↓
전처리 완료 CSV (raw/YYYYMMDD/ke30_*_전처리완료.csv)
    ↓
[create_treemap_data.py]
    ↓
트리맵 JS 파일 (public/treemap_data_YYYYMMDD.js, data_YYYYMMDD.js)
```

### 대시보드 섹션별 데이터 요구사항
1. **전체 현황 섹션**
   - 브랜드별 매출/이익 집계
   - KPI 카드 (실판매출, 직접이익 등)
   - 브랜드 기여도 차트
   - 레이더 차트
   - 누적 트렌드

2. **브랜드별 분석 섹션**
   - 브랜드별 KPI
   - 주차별 트렌드
   - 채널별 손익 테이블
   - 트리맵 (채널별/아이템별)
   - 아이템 분석

3. **재무 보고서 (PL 테이블)**
   - 매출, 원가, 직접비, 영업비, 이익 등

---

## 💡 권장 아키텍처: **2단계 접근 방식**

### ✅ **추천: 전처리된 데이터 기반 접근**

```
┌─────────────────────────────────────────┐
│ 1단계: 공통 전처리 (한 번만 실행)        │
├─────────────────────────────────────────┤
│ 로데이터 → 전처리 완료 CSV               │
│ - 브랜드 공란 제거                       │
│ - 피벗 집계 (브랜드, 시즌, 채널, 아이템) │
│ - 마스터 매핑 (채널명, 아이템 분류)     │
│ - 데이터 정규화                         │
└─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────┐
│ 2단계: 섹션별 데이터 생성 (각각 실행)    │
├─────────────────────────────────────────┤
│ 전처리 완료 CSV → 섹션별 JS/JSON 파일   │
│                                         │
│ - create_treemap_data.py               │
│   → 트리맵 데이터                       │
│                                         │
│ - create_overview_data.py (신규)       │
│   → 전체 현황 KPI, 차트 데이터          │
│                                         │
│ - create_brand_analysis_data.py (신규)  │
│   → 브랜드별 분석 데이터                │
│                                         │
│ - create_financial_report_data.py (신규)│
│   → PL 테이블 데이터                    │
└─────────────────────────────────────────┘
```

---

## 🎯 권장 이유

### ✅ **전처리된 데이터 기반 접근의 장점**

1. **성능 최적화**
   - 로데이터는 수만~수십만 행
   - 전처리 후 데이터는 수천 행으로 감소
   - 각 섹션별 스크립트 실행 시간 단축

2. **유지보수 용이**
   - 전처리 로직 변경 시 한 곳만 수정
   - 섹션별 로직은 독립적으로 수정 가능
   - 디버깅이 쉬움

3. **재사용성**
   - 전처리된 데이터를 여러 섹션에서 공유
   - 일관성 있는 데이터 사용

4. **확장성**
   - 새로운 섹션 추가 시 전처리된 데이터만 읽으면 됨
   - 섹션별 스크립트를 독립적으로 개발 가능

5. **에러 처리**
   - 전처리 단계에서 데이터 검증
   - 섹션별 스크립트는 집계 로직에만 집중

### ❌ **각 섹션별로 로데이터 집계부터 하는 방식의 단점**

1. **중복 작업**
   - 각 섹션마다 동일한 전처리 로직 반복
   - 코드 중복 증가

2. **성능 저하**
   - 로데이터를 여러 번 읽고 처리
   - 실행 시간 증가

3. **일관성 문제**
   - 섹션별로 전처리 로직이 다를 수 있음
   - 데이터 불일치 가능성

4. **유지보수 어려움**
   - 전처리 로직 변경 시 모든 섹션 스크립트 수정 필요

---

## 📋 구체적인 구현 방안

### 현재 구조 (이미 구현됨)
```
scripts/
├── process_ke30_current_year.py  ✅ 전처리 (당년)
├── create_treemap_data.py        ✅ 트리맵 데이터 생성
└── process_202511R_plan.py       ✅ 계획 데이터 전처리
```

### 권장 추가 구조
```
scripts/
├── process_ke30_current_year.py      ✅ 전처리 (당년)
├── process_ke30_previous_year.py    🔄 전처리 (전년) - 신규
├── process_plan_data.py             🔄 전처리 (계획) - 개선
│
├── create_treemap_data.py           ✅ 트리맵 데이터
├── create_overview_data.py          🆕 전체 현황 데이터
├── create_brand_analysis_data.py    🆕 브랜드별 분석 데이터
├── create_financial_report_data.py  🆕 재무 보고서 데이터
└── create_weekly_trend_data.py      🆕 주차별 트렌드 데이터
```

### 데이터 흐름 예시

#### 예시 1: 전체 현황 KPI 생성
```python
# scripts/create_overview_data.py
def create_overview_kpi(processed_csv_path):
    """
    전처리 완료 CSV → 전체 현황 KPI 데이터
    """
    df = pd.read_csv(processed_csv_path)
    
    # 브랜드별 집계
    brand_summary = df.groupby('브랜드').agg({
        '실판매액': 'sum',
        '직접이익': 'sum',
        # ...
    })
    
    # 전체 합계
    total_sales = df['실판매액'].sum()
    total_profit = df['직접이익'].sum()
    
    return {
        'brandSummary': brand_summary.to_dict(),
        'totalSales': total_sales,
        'totalProfit': total_profit,
        # ...
    }
```

#### 예시 2: 재무 보고서 데이터 생성
```python
# scripts/create_financial_report_data.py
def create_financial_report(processed_csv_path, plan_csv_path):
    """
    전처리 완료 CSV + 계획 CSV → 재무 보고서 데이터
    """
    df_current = pd.read_csv(processed_csv_path)
    df_plan = pd.read_csv(plan_csv_path)
    
    # 당년 집계
    current_summary = aggregate_by_brand(df_current)
    
    # 계획 데이터와 비교
    comparison = compare_with_plan(current_summary, df_plan)
    
    return comparison
```

---

## 🚀 실행 순서

### 배치 파일 구조 (권장)
```batch
@echo off
REM 1단계: 전처리 (공통)
python scripts\process_ke30_current_year.py
python scripts\process_ke30_previous_year.py
python scripts\process_plan_data.py

REM 2단계: 섹션별 데이터 생성
python scripts\create_treemap_data.py %DATE%
python scripts\create_overview_data.py %DATE%
python scripts\create_brand_analysis_data.py %DATE%
python scripts\create_financial_report_data.py %DATE%
python scripts\create_weekly_trend_data.py %DATE%
```

---

## 📊 데이터 파일 구조

### 전처리 완료 파일 (공통)
```
raw/YYYYMMDD/
├── ke30_YYYYMMDD_YYYYMM_전처리완료.csv  (당년)
├── ke30_prev_YYYYMMDD_전처리완료.csv     (전년)
└── plan_YYYYMMDD_전처리완료.csv          (계획)
```

### 섹션별 출력 파일
```
public/
├── treemap_data_YYYYMMDD.js          (트리맵)
├── overview_data_YYYYMMDD.js          (전체 현황)
├── brand_analysis_data_YYYYMMDD.js    (브랜드별 분석)
├── financial_report_data_YYYYMMDD.js  (재무 보고서)
└── weekly_trend_data_YYYYMMDD.js      (주차별 트렌드)
```

---

## ✅ 최종 권장사항

**전처리된 데이터를 기반으로 각 섹션별 로직을 작성하는 것을 강력히 권장합니다.**

### 이유:
1. ✅ 성능: 한 번만 전처리하고 여러 섹션에서 재사용
2. ✅ 유지보수: 전처리 로직 변경 시 한 곳만 수정
3. ✅ 일관성: 모든 섹션이 동일한 전처리 데이터 사용
4. ✅ 확장성: 새로운 섹션 추가가 쉬움
5. ✅ 디버깅: 문제 발생 시 단계별로 확인 가능

### 구현 순서:
1. **1단계**: 전처리 스크립트 완성 (이미 완료 ✅)
2. **2단계**: 각 섹션별 데이터 생성 스크립트 작성
3. **3단계**: 배치 파일로 통합 실행

---

## 🔄 대안: 하이브리드 접근

일부 섹션이 완전히 다른 집계가 필요한 경우:

```python
# 예: 특정 섹션만 로데이터에서 직접 집계
def create_special_section_data(raw_csv_path):
    """
    특수한 집계가 필요한 경우에만 로데이터 직접 사용
    """
    df_raw = pd.read_csv(raw_csv_path)
    # 특수 집계 로직
    return special_aggregation(df_raw)
```

하지만 **대부분의 경우 전처리된 데이터로 충분**합니다.



